#include "tensorflow/core/framework/op.h"
#include "tensorflow/core/framework/op_kernel.h"
#include "tensorflow/core/framework/shape_inference.h"
#include <iostream>


using namespace tensorflow;

inline float signed_log_x_plus_one(float x) {
  return float((x>0)-(x<0)) * std::log(std::abs(x) + 1.0);
}

inline float min_max_normalize(float x, float v_min, float v_max) {
  return (std::max(v_min, std::min(x, v_max)) - v_min) / (v_max - v_min);
}

class LogMinMaxOp : public OpKernel {
public:
    explicit LogMinMaxOp(OpKernelConstruction* context) : OpKernel(context) {
        OP_REQUIRES_OK(context, context->GetAttr("LogMin", &log_min_));
        OP_REQUIRES_OK(context, context->GetAttr("LogMax", &log_max_));
    }
    void Compute(OpKernelContext* context) override {
        const Tensor& x_tensor = context->input(0);
        auto x = x_tensor.flat<float>();
        Tensor* y_tensor = nullptr;
        int64 batch_size = x.size();
        OP_REQUIRES_OK(context, context->allocate_output(0, x_tensor.shape(),
                                                &y_tensor));
        const float* p1 = &x(0);
        float *p2 = &y_tensor->flat<float>()(0);
        for (int i = 0; i < batch_size; ++i, ++p1, ++p2) {
            *p2 = min_max_normalize(signed_log_x_plus_one(*p1), log_min_, log_max_);
        }
    }
private:
    float log_min_ = 0, log_max_ = 0;
};

REGISTER_OP("LogMinMax")
    .Input("x: float32")
    .Output("y: float32")
    .Attr("LogMin: float")
    .Attr("LogMax: float")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
        c->set_output(0, c->input(0));
        return Status::OK();
  });

REGISTER_KERNEL_BUILDER(Name("LogMinMax").Device(DEVICE_CPU), LogMinMaxOp)
